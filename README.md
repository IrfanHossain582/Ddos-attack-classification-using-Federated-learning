# ğŸ›¡ï¸ DDoS Attack Classification (12-Class) with Hierarchical Model & Federated Learning

This project focuses on detecting and classifying **12 different classes of DDoS attacks** using a combination of advanced preprocessing techniques, hierarchical modeling, and federated learning.
The full pipeline includes **data preprocessing â†’ balancing â†’ hierarchical classification â†’ advanced ML models â†’ federated training â†’ evaluation**.

---

## ğŸ”§ **Key Features**

* âœ” Balanced dataset using **SMOTE**
* âœ” Full preprocessing pipeline
* âœ” **Hierarchical Classification Model**
* âœ” Specialized handling for **SYN Flood & Synonymous Flood** attacks
* âœ” **Federated Learning** implementation
* âœ” Achieved **98% accuracy**
* âœ” Robust performance across all 12 classes

---

## ğŸ” **Data Preprocessing Pipeline**

### **1. Duplicate Removal**

Ensures the dataset contains only unique samples and eliminates redundancy.

### **2. Null Value Removal**

All rows with missing values were removed for clean training.

### **3. Label Encoding**

Converts categorical attack names into numeric classes.

### **4. StandardScaler**

Standardizes all numerical features to boost model stability.

### **5. SMOTE (Synthetic Minority Oversampling Technique)**

Balances all 12 attack classes, ensuring equal representation.

---

## ğŸ§© **Hierarchical Classification Model**

A **two-level hybrid model** was designed:

---

### ğŸ”¹ **Level 1 â€” Specialized Binary Classification for SYN-Related Attacks**

The following two classes show very similar traffic patterns and often get misclassified:

* **SYN Flood**
* **Synonymous Flood**

To accurately separate them, a **Random Forest classifier** is trained **only on these two classes**.

ğŸ“Œ **Why Random Forest?**

* Excellent for handling noisy cybersecurity datasets
* Works well for binary and multi-class problems
* Reduces overfitting through ensemble learning
* Automatically captures nonlinear relations
* Robust performance and easy to tune

---

### ğŸ”¹ **Level 2 â€” General Classification for All 12 Classes**

For full multiclass classification, an **XGBoost model** is used on the entire dataset after preprocessing.

ğŸ“Œ **Why XGBoost?**

* Exceptional performance on tabular network traffic data
* Handles class imbalance (especially after SMOTE)
* Resistant to overfitting
* Fast training and high accuracy
* Feature importance plots provide interpretability

---

## ğŸŒ **Federated Learning Implementation**

To support privacy-preserving cybersecurity analytics, this project includes a simulated **Federated Learning** setup.

### **Federated Setup**

* Multiple clients train on different data partitions
* Only model weights/gradients are shared
* No raw packet or flow data is exposed
* Aggregation is done via **Federated Averaging (FedAvg)**

ğŸ“Œ **Why Federated Learning?**

* Ideal for sensitive and distributed network datasets
* Protects user or organization data
* Allows collaboration across multiple nodes securely

---

## ğŸ“Š **Results**

### ğŸ¯ **Final Accuracy: *98%***

* The hierarchical design significantly improves the accuracy of **SYN Flood** vs **Synonymous Flood** predictions.
* XGBoost delivers strong multiclass classification across all 12 attack types.
* Federated learning retains model quality while preserving privacy.

---

## ğŸ“ˆ **Performance Highlights**

* âœ” Superior SYN-related attack separation via Random Forest
* âœ” Balanced dataset using SMOTE leads to stable predictions
* âœ” High generalization from federated setup
* âœ” Lower false positives and false negatives across classes

---

## ğŸ“ **Recommended Project Structure**

```
â””â”€â”€ ddos-hierarchical-classification/
    â”œâ”€â”€ data/
    â”œâ”€â”€ preprocessing/
    â”œâ”€â”€ federated/
    â”œâ”€â”€ models/
    â”œâ”€â”€ notebooks/
    â”œâ”€â”€ README.md
    â””â”€â”€ requirements.txt
```

---

## âš™ï¸ **Technologies Used**

* Python
* Pandas, NumPy
* Scikit-Learn
* Imbalanced-Learn (SMOTE)
* Random Forest (Binary Classification)
* XGBoost (Multiclass Classification)
* Federated Learning (FedAvg Simulation)
* Matplotlib, Seaborn


